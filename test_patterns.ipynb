{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d56f2b-cd4d-4166-b923-068f423a48e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check:\n",
    "# 1. make sure that the update works for the score tensor, the values in the tensor, etc\n",
    "# 2. make sure the new win loss from the search tree is accurately represented as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76388a02-2834-4bcc-a97c-a73cf0835a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import datetime\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import copy\n",
    "from importlib import reload\n",
    "import torch\n",
    "import int_to_board\n",
    "import pickle\n",
    "\n",
    "reload(int_to_board)\n",
    "\n",
    "import game\n",
    "reload(game)\n",
    "\n",
    "import plotting\n",
    "reload(plotting)\n",
    "\n",
    "import mcts.mcts\n",
    "reload(mcts.mcts)\n",
    "\n",
    "import mcts.networks\n",
    "reload(mcts.networks)\n",
    "\n",
    "import mcts.agent\n",
    "reload(mcts.agent)\n",
    "\n",
    "import augmentor\n",
    "reload(augmentor)\n",
    "\n",
    "from game import Patterns\n",
    "from plotting import PatternPlotter\n",
    "\n",
    "from mcts.mcts import Tree, Node\n",
    "from mcts.networks import PatternsNet\n",
    "from mcts.agent import Agent\n",
    "\n",
    "from augmentor import StateAugmentor\n",
    "\n",
    "# rseed = 12387623\n",
    "# random.seed(rseed)\n",
    "# torch.manual_seed(rseed)\n",
    "# np.random.seed(rseed)\n",
    "\n",
    "my_device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2dfc90-4ff1-4ddf-81b1-3a8eba47e989",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_network = PatternsNet(\n",
    "    in_channels=47,\n",
    "    # EDIT: new shape of the channels\n",
    "    # [board_tensor, order_tensor, bowl_tensor, placing_tensor, score_tensor, token_value_tensor]\n",
    "    # 47 for the number of state planes: \n",
    "    # 18 for the board (6 colors per passive, p1, p2)\n",
    "    # 12 for the order (6 per player, float layers)\n",
    "    # 12 for bowl tokens (6 per player, indicating current token)\n",
    "    # 1 for is no more placing\n",
    "    # 2 for score tensor (1 per player, float layers)\n",
    "    # 2 for token value tensor (1 per player, float for the relative score of the token in the bowl)\n",
    "    out_channels=128,  \n",
    "    # 49076716 params if 128 out channels used\n",
    "    # 12295468 params if 64 is used instead\n",
    ")\n",
    "\n",
    "# sum(p.numel() for p in my_network.parameters() if p.requires_grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff38fa5c-223a-43b4-acb4-5b59fe459c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load up previous best networks to help play the games (lets see how it does!).\n",
    "# in time, have best of a generation playing against each other!\n",
    "network_path = os.path.join(Path.cwd(), 'saved_networks', 'v3', '2025_07_10_03_58.pt')\n",
    "my_network = PatternsNet(in_channels=47, out_channels=128)\n",
    "my_network.load_state_dict(torch.load(network_path, weights_only=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56f0822-bb5f-4af5-8d0d-8fbc53948caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a random game first:\n",
    "my_game = Patterns()\n",
    "num_moves = 40\n",
    "\n",
    "for _ in range(num_moves):\n",
    "    actions = my_game.get_actions()\n",
    "    action = random.choice(actions)\n",
    "    is_terminal, result = my_game.step(action)\n",
    "    \n",
    "    if is_terminal:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e03d617d-b189-4801-8d80-42398e8c28f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TREES = 1024\n",
    "TARGET_GAMES = 1024\n",
    "NUM_IT = 1\n",
    "SCHEDULE = [\n",
    "    (0, 0), # explore randomly for the first moves:\n",
    "    (10, 250), # explore with search tree after depth 10:\n",
    "]\n",
    "SAVE_DEPTH = 3\n",
    "\n",
    "TOPN = 6\n",
    "RANDN = 4\n",
    "SELECTION_TEMP = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb47dee-85e2-4f48-9cc5-e728d31bbc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_agent = Agent(\n",
    "        agent_id='1', # not relevant for a single machine:\n",
    "        network = my_network,\n",
    "        device = my_device,\n",
    "        num_trees = 1, # number of in series trees to use:\n",
    "        target_games = 1, # total number of games in the data set\n",
    "        selection_temperature = SELECTION_TEMP,\n",
    "        topn=TOPN, # only explore the top 5 best moves\n",
    "        randn=RANDN, # explore an additional 5 random moves\n",
    "        save_depth=SAVE_DEPTH, # for this, only save the final state and move\n",
    "        explore_steps_schedule=SCHEDULE,  \n",
    "        debug=False, \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bb885d2-2d54-44e9-8a4b-9be7627c347e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating initial games:\n",
      "Evaluating tensor states...\n",
      "Provisioning inference to root nodes...\n",
      "3 games have been completed!\n",
      "9 games have been completed!\n",
      "16 games have been completed!\n",
      "24 games have been completed!\n",
      "36 games have been completed!\n",
      "43 games have been completed!\n",
      "51 games have been completed!\n",
      "58 games have been completed!\n",
      "60 games have been completed!\n",
      "61 games have been completed!\n",
      "62 games have been completed!\n",
      "63 games have been completed!\n",
      "64 games have been completed!\n",
      "67 games have been completed!\n",
      "68 games have been completed!\n",
      "69 games have been completed!\n",
      "70 games have been completed!\n",
      "71 games have been completed!\n",
      "72 games have been completed!\n",
      "73 games have been completed!\n",
      "74 games have been completed!\n",
      "75 games have been completed!\n",
      "76 games have been completed!\n",
      "77 games have been completed!\n",
      "78 games have been completed!\n",
      "79 games have been completed!\n",
      "80 games have been completed!\n",
      "81 games have been completed!\n",
      "82 games have been completed!\n",
      "83 games have been completed!\n",
      "84 games have been completed!\n",
      "85 games have been completed!\n",
      "86 games have been completed!\n",
      "87 games have been completed!\n",
      "88 games have been completed!\n",
      "89 games have been completed!\n",
      "90 games have been completed!\n",
      "91 games have been completed!\n",
      "92 games have been completed!\n",
      "93 games have been completed!\n",
      "94 games have been completed!\n",
      "95 games have been completed!\n",
      "96 games have been completed!\n",
      "97 games have been completed!\n",
      "98 games have been completed!\n",
      "99 games have been completed!\n",
      "100 games have been completed!\n",
      "101 games have been completed!\n",
      "102 games have been completed!\n",
      "103 games have been completed!\n",
      "104 games have been completed!\n",
      "105 games have been completed!\n",
      "107 games have been completed!\n",
      "108 games have been completed!\n",
      "109 games have been completed!\n",
      "110 games have been completed!\n",
      "111 games have been completed!\n",
      "112 games have been completed!\n",
      "113 games have been completed!\n",
      "114 games have been completed!\n",
      "115 games have been completed!\n",
      "116 games have been completed!\n",
      "117 games have been completed!\n",
      "118 games have been completed!\n",
      "119 games have been completed!\n",
      "121 games have been completed!\n",
      "122 games have been completed!\n",
      "123 games have been completed!\n",
      "124 games have been completed!\n",
      "125 games have been completed!\n",
      "126 games have been completed!\n",
      "127 games have been completed!\n",
      "129 games have been completed!\n",
      "130 games have been completed!\n",
      "131 games have been completed!\n",
      "132 games have been completed!\n",
      "133 games have been completed!\n",
      "134 games have been completed!\n",
      "135 games have been completed!\n",
      "136 games have been completed!\n",
      "137 games have been completed!\n",
      "138 games have been completed!\n",
      "139 games have been completed!\n",
      "140 games have been completed!\n",
      "141 games have been completed!\n",
      "142 games have been completed!\n",
      "144 games have been completed!\n",
      "145 games have been completed!\n",
      "146 games have been completed!\n",
      "147 games have been completed!\n",
      "148 games have been completed!\n",
      "150 games have been completed!\n",
      "151 games have been completed!\n",
      "152 games have been completed!\n",
      "153 games have been completed!\n",
      "154 games have been completed!\n",
      "155 games have been completed!\n",
      "156 games have been completed!\n",
      "157 games have been completed!\n",
      "158 games have been completed!\n",
      "159 games have been completed!\n",
      "160 games have been completed!\n",
      "161 games have been completed!\n",
      "162 games have been completed!\n",
      "163 games have been completed!\n",
      "164 games have been completed!\n",
      "165 games have been completed!\n",
      "166 games have been completed!\n",
      "167 games have been completed!\n",
      "168 games have been completed!\n",
      "169 games have been completed!\n",
      "170 games have been completed!\n",
      "171 games have been completed!\n",
      "172 games have been completed!\n",
      "173 games have been completed!\n",
      "174 games have been completed!\n",
      "175 games have been completed!\n",
      "176 games have been completed!\n",
      "177 games have been completed!\n",
      "178 games have been completed!\n",
      "179 games have been completed!\n",
      "180 games have been completed!\n",
      "181 games have been completed!\n",
      "182 games have been completed!\n",
      "183 games have been completed!\n",
      "184 games have been completed!\n",
      "186 games have been completed!\n",
      "187 games have been completed!\n",
      "188 games have been completed!\n",
      "190 games have been completed!\n",
      "192 games have been completed!\n",
      "193 games have been completed!\n",
      "194 games have been completed!\n",
      "195 games have been completed!\n",
      "196 games have been completed!\n",
      "197 games have been completed!\n",
      "198 games have been completed!\n",
      "200 games have been completed!\n",
      "201 games have been completed!\n",
      "202 games have been completed!\n",
      "203 games have been completed!\n",
      "206 games have been completed!\n",
      "207 games have been completed!\n",
      "208 games have been completed!\n",
      "209 games have been completed!\n",
      "210 games have been completed!\n",
      "211 games have been completed!\n",
      "212 games have been completed!\n",
      "213 games have been completed!\n",
      "214 games have been completed!\n",
      "215 games have been completed!\n",
      "216 games have been completed!\n",
      "217 games have been completed!\n",
      "219 games have been completed!\n",
      "220 games have been completed!\n",
      "221 games have been completed!\n",
      "223 games have been completed!\n",
      "224 games have been completed!\n",
      "225 games have been completed!\n",
      "226 games have been completed!\n",
      "227 games have been completed!\n",
      "228 games have been completed!\n",
      "229 games have been completed!\n",
      "231 games have been completed!\n",
      "233 games have been completed!\n",
      "235 games have been completed!\n",
      "236 games have been completed!\n",
      "237 games have been completed!\n",
      "238 games have been completed!\n",
      "239 games have been completed!\n",
      "241 games have been completed!\n",
      "243 games have been completed!\n",
      "244 games have been completed!\n",
      "245 games have been completed!\n",
      "246 games have been completed!\n",
      "247 games have been completed!\n",
      "249 games have been completed!\n",
      "250 games have been completed!\n",
      "251 games have been completed!\n",
      "252 games have been completed!\n",
      "253 games have been completed!\n",
      "254 games have been completed!\n",
      "255 games have been completed!\n",
      "256 games have been completed!\n",
      "257 games have been completed!\n",
      "258 games have been completed!\n",
      "259 games have been completed!\n",
      "260 games have been completed!\n",
      "261 games have been completed!\n",
      "262 games have been completed!\n",
      "263 games have been completed!\n",
      "264 games have been completed!\n",
      "265 games have been completed!\n",
      "266 games have been completed!\n",
      "268 games have been completed!\n",
      "269 games have been completed!\n",
      "270 games have been completed!\n",
      "272 games have been completed!\n",
      "275 games have been completed!\n",
      "276 games have been completed!\n",
      "277 games have been completed!\n",
      "278 games have been completed!\n",
      "279 games have been completed!\n",
      "280 games have been completed!\n",
      "281 games have been completed!\n",
      "282 games have been completed!\n",
      "285 games have been completed!\n",
      "286 games have been completed!\n",
      "287 games have been completed!\n",
      "288 games have been completed!\n",
      "289 games have been completed!\n",
      "290 games have been completed!\n",
      "291 games have been completed!\n",
      "292 games have been completed!\n",
      "293 games have been completed!\n",
      "294 games have been completed!\n",
      "295 games have been completed!\n",
      "296 games have been completed!\n",
      "297 games have been completed!\n",
      "298 games have been completed!\n",
      "299 games have been completed!\n",
      "300 games have been completed!\n",
      "302 games have been completed!\n",
      "303 games have been completed!\n",
      "304 games have been completed!\n",
      "305 games have been completed!\n",
      "306 games have been completed!\n",
      "308 games have been completed!\n",
      "309 games have been completed!\n",
      "310 games have been completed!\n",
      "311 games have been completed!\n",
      "312 games have been completed!\n",
      "313 games have been completed!\n",
      "314 games have been completed!\n",
      "315 games have been completed!\n",
      "316 games have been completed!\n",
      "317 games have been completed!\n",
      "318 games have been completed!\n",
      "319 games have been completed!\n",
      "320 games have been completed!\n",
      "321 games have been completed!\n",
      "322 games have been completed!\n",
      "326 games have been completed!\n",
      "327 games have been completed!\n",
      "328 games have been completed!\n",
      "329 games have been completed!\n",
      "330 games have been completed!\n",
      "332 games have been completed!\n",
      "333 games have been completed!\n",
      "334 games have been completed!\n",
      "335 games have been completed!\n",
      "336 games have been completed!\n",
      "337 games have been completed!\n",
      "338 games have been completed!\n",
      "339 games have been completed!\n",
      "340 games have been completed!\n",
      "341 games have been completed!\n",
      "342 games have been completed!\n",
      "343 games have been completed!\n",
      "344 games have been completed!\n",
      "346 games have been completed!\n",
      "347 games have been completed!\n",
      "348 games have been completed!\n",
      "349 games have been completed!\n",
      "351 games have been completed!\n",
      "352 games have been completed!\n",
      "353 games have been completed!\n",
      "354 games have been completed!\n",
      "355 games have been completed!\n",
      "356 games have been completed!\n",
      "357 games have been completed!\n",
      "359 games have been completed!\n",
      "360 games have been completed!\n",
      "361 games have been completed!\n",
      "363 games have been completed!\n",
      "366 games have been completed!\n",
      "367 games have been completed!\n",
      "368 games have been completed!\n",
      "371 games have been completed!\n",
      "372 games have been completed!\n",
      "373 games have been completed!\n",
      "374 games have been completed!\n",
      "375 games have been completed!\n",
      "376 games have been completed!\n",
      "377 games have been completed!\n",
      "378 games have been completed!\n",
      "379 games have been completed!\n",
      "380 games have been completed!\n",
      "381 games have been completed!\n",
      "382 games have been completed!\n",
      "383 games have been completed!\n",
      "384 games have been completed!\n",
      "385 games have been completed!\n",
      "387 games have been completed!\n",
      "389 games have been completed!\n",
      "390 games have been completed!\n",
      "391 games have been completed!\n",
      "392 games have been completed!\n",
      "394 games have been completed!\n",
      "395 games have been completed!\n",
      "396 games have been completed!\n",
      "398 games have been completed!\n",
      "402 games have been completed!\n",
      "403 games have been completed!\n",
      "404 games have been completed!\n",
      "405 games have been completed!\n",
      "406 games have been completed!\n",
      "409 games have been completed!\n",
      "410 games have been completed!\n",
      "411 games have been completed!\n",
      "412 games have been completed!\n",
      "413 games have been completed!\n",
      "414 games have been completed!\n",
      "415 games have been completed!\n",
      "416 games have been completed!\n",
      "417 games have been completed!\n",
      "418 games have been completed!\n",
      "420 games have been completed!\n",
      "421 games have been completed!\n",
      "422 games have been completed!\n",
      "423 games have been completed!\n",
      "424 games have been completed!\n",
      "427 games have been completed!\n",
      "428 games have been completed!\n",
      "429 games have been completed!\n",
      "430 games have been completed!\n",
      "431 games have been completed!\n",
      "433 games have been completed!\n",
      "435 games have been completed!\n",
      "437 games have been completed!\n",
      "438 games have been completed!\n",
      "439 games have been completed!\n",
      "440 games have been completed!\n",
      "442 games have been completed!\n",
      "444 games have been completed!\n",
      "445 games have been completed!\n",
      "446 games have been completed!\n",
      "448 games have been completed!\n",
      "451 games have been completed!\n",
      "452 games have been completed!\n",
      "453 games have been completed!\n",
      "454 games have been completed!\n",
      "455 games have been completed!\n",
      "456 games have been completed!\n",
      "457 games have been completed!\n",
      "459 games have been completed!\n",
      "462 games have been completed!\n",
      "463 games have been completed!\n",
      "464 games have been completed!\n",
      "465 games have been completed!\n",
      "467 games have been completed!\n",
      "468 games have been completed!\n",
      "469 games have been completed!\n",
      "470 games have been completed!\n",
      "471 games have been completed!\n",
      "473 games have been completed!\n",
      "474 games have been completed!\n",
      "475 games have been completed!\n",
      "476 games have been completed!\n",
      "477 games have been completed!\n",
      "479 games have been completed!\n",
      "482 games have been completed!\n",
      "484 games have been completed!\n",
      "485 games have been completed!\n",
      "486 games have been completed!\n",
      "487 games have been completed!\n",
      "489 games have been completed!\n",
      "491 games have been completed!\n",
      "495 games have been completed!\n",
      "496 games have been completed!\n",
      "497 games have been completed!\n",
      "498 games have been completed!\n",
      "499 games have been completed!\n",
      "500 games have been completed!\n",
      "501 games have been completed!\n",
      "502 games have been completed!\n",
      "503 games have been completed!\n",
      "506 games have been completed!\n",
      "507 games have been completed!\n",
      "508 games have been completed!\n",
      "510 games have been completed!\n",
      "513 games have been completed!\n",
      "514 games have been completed!\n",
      "515 games have been completed!\n",
      "516 games have been completed!\n",
      "517 games have been completed!\n",
      "518 games have been completed!\n",
      "519 games have been completed!\n",
      "520 games have been completed!\n",
      "521 games have been completed!\n",
      "522 games have been completed!\n",
      "524 games have been completed!\n",
      "526 games have been completed!\n",
      "527 games have been completed!\n",
      "529 games have been completed!\n",
      "532 games have been completed!\n",
      "533 games have been completed!\n",
      "535 games have been completed!\n",
      "536 games have been completed!\n",
      "538 games have been completed!\n",
      "539 games have been completed!\n",
      "540 games have been completed!\n",
      "541 games have been completed!\n",
      "542 games have been completed!\n",
      "544 games have been completed!\n",
      "546 games have been completed!\n",
      "549 games have been completed!\n",
      "550 games have been completed!\n",
      "551 games have been completed!\n",
      "552 games have been completed!\n",
      "553 games have been completed!\n",
      "555 games have been completed!\n",
      "556 games have been completed!\n",
      "558 games have been completed!\n",
      "561 games have been completed!\n",
      "564 games have been completed!\n",
      "565 games have been completed!\n",
      "568 games have been completed!\n",
      "569 games have been completed!\n",
      "572 games have been completed!\n",
      "573 games have been completed!\n",
      "574 games have been completed!\n",
      "576 games have been completed!\n",
      "577 games have been completed!\n",
      "578 games have been completed!\n",
      "580 games have been completed!\n",
      "581 games have been completed!\n",
      "582 games have been completed!\n",
      "583 games have been completed!\n",
      "584 games have been completed!\n",
      "586 games have been completed!\n",
      "588 games have been completed!\n",
      "591 games have been completed!\n",
      "593 games have been completed!\n",
      "594 games have been completed!\n",
      "596 games have been completed!\n",
      "599 games have been completed!\n",
      "600 games have been completed!\n",
      "601 games have been completed!\n",
      "603 games have been completed!\n",
      "604 games have been completed!\n",
      "606 games have been completed!\n",
      "607 games have been completed!\n",
      "608 games have been completed!\n",
      "609 games have been completed!\n",
      "611 games have been completed!\n",
      "613 games have been completed!\n",
      "616 games have been completed!\n",
      "617 games have been completed!\n",
      "619 games have been completed!\n",
      "620 games have been completed!\n",
      "621 games have been completed!\n",
      "622 games have been completed!\n",
      "623 games have been completed!\n",
      "624 games have been completed!\n",
      "626 games have been completed!\n",
      "627 games have been completed!\n",
      "629 games have been completed!\n",
      "631 games have been completed!\n",
      "633 games have been completed!\n",
      "634 games have been completed!\n",
      "635 games have been completed!\n",
      "637 games have been completed!\n",
      "638 games have been completed!\n",
      "640 games have been completed!\n",
      "641 games have been completed!\n",
      "642 games have been completed!\n",
      "643 games have been completed!\n",
      "644 games have been completed!\n",
      "645 games have been completed!\n",
      "647 games have been completed!\n",
      "648 games have been completed!\n",
      "649 games have been completed!\n",
      "650 games have been completed!\n",
      "651 games have been completed!\n",
      "652 games have been completed!\n",
      "653 games have been completed!\n",
      "654 games have been completed!\n",
      "655 games have been completed!\n",
      "657 games have been completed!\n",
      "659 games have been completed!\n",
      "661 games have been completed!\n",
      "662 games have been completed!\n",
      "663 games have been completed!\n",
      "664 games have been completed!\n",
      "665 games have been completed!\n",
      "666 games have been completed!\n",
      "667 games have been completed!\n",
      "669 games have been completed!\n",
      "671 games have been completed!\n",
      "672 games have been completed!\n",
      "673 games have been completed!\n",
      "675 games have been completed!\n",
      "676 games have been completed!\n",
      "677 games have been completed!\n",
      "678 games have been completed!\n",
      "679 games have been completed!\n",
      "680 games have been completed!\n",
      "681 games have been completed!\n",
      "682 games have been completed!\n",
      "683 games have been completed!\n",
      "685 games have been completed!\n",
      "686 games have been completed!\n",
      "687 games have been completed!\n",
      "688 games have been completed!\n",
      "689 games have been completed!\n",
      "690 games have been completed!\n",
      "691 games have been completed!\n",
      "692 games have been completed!\n",
      "695 games have been completed!\n",
      "696 games have been completed!\n",
      "697 games have been completed!\n",
      "698 games have been completed!\n",
      "700 games have been completed!\n",
      "701 games have been completed!\n",
      "705 games have been completed!\n",
      "706 games have been completed!\n",
      "707 games have been completed!\n",
      "708 games have been completed!\n",
      "709 games have been completed!\n",
      "710 games have been completed!\n",
      "713 games have been completed!\n",
      "714 games have been completed!\n",
      "715 games have been completed!\n",
      "717 games have been completed!\n",
      "719 games have been completed!\n",
      "720 games have been completed!\n",
      "721 games have been completed!\n",
      "724 games have been completed!\n",
      "725 games have been completed!\n",
      "727 games have been completed!\n",
      "729 games have been completed!\n",
      "733 games have been completed!\n",
      "734 games have been completed!\n",
      "735 games have been completed!\n",
      "739 games have been completed!\n",
      "741 games have been completed!\n",
      "742 games have been completed!\n",
      "745 games have been completed!\n",
      "747 games have been completed!\n",
      "750 games have been completed!\n",
      "751 games have been completed!\n",
      "752 games have been completed!\n",
      "753 games have been completed!\n",
      "754 games have been completed!\n",
      "755 games have been completed!\n",
      "757 games have been completed!\n",
      "759 games have been completed!\n",
      "760 games have been completed!\n",
      "761 games have been completed!\n",
      "763 games have been completed!\n",
      "764 games have been completed!\n",
      "765 games have been completed!\n",
      "768 games have been completed!\n",
      "769 games have been completed!\n",
      "771 games have been completed!\n",
      "772 games have been completed!\n",
      "773 games have been completed!\n",
      "775 games have been completed!\n",
      "777 games have been completed!\n",
      "778 games have been completed!\n",
      "779 games have been completed!\n",
      "780 games have been completed!\n",
      "781 games have been completed!\n",
      "782 games have been completed!\n",
      "784 games have been completed!\n",
      "785 games have been completed!\n",
      "786 games have been completed!\n",
      "787 games have been completed!\n",
      "788 games have been completed!\n",
      "789 games have been completed!\n",
      "791 games have been completed!\n",
      "792 games have been completed!\n",
      "793 games have been completed!\n",
      "794 games have been completed!\n",
      "798 games have been completed!\n",
      "799 games have been completed!\n",
      "800 games have been completed!\n",
      "801 games have been completed!\n",
      "803 games have been completed!\n",
      "805 games have been completed!\n",
      "806 games have been completed!\n",
      "807 games have been completed!\n",
      "808 games have been completed!\n",
      "809 games have been completed!\n",
      "810 games have been completed!\n",
      "811 games have been completed!\n",
      "812 games have been completed!\n",
      "813 games have been completed!\n",
      "815 games have been completed!\n",
      "816 games have been completed!\n",
      "817 games have been completed!\n",
      "818 games have been completed!\n",
      "819 games have been completed!\n",
      "820 games have been completed!\n",
      "821 games have been completed!\n",
      "822 games have been completed!\n",
      "823 games have been completed!\n",
      "824 games have been completed!\n",
      "826 games have been completed!\n",
      "827 games have been completed!\n",
      "830 games have been completed!\n",
      "831 games have been completed!\n",
      "832 games have been completed!\n",
      "833 games have been completed!\n",
      "834 games have been completed!\n",
      "835 games have been completed!\n",
      "837 games have been completed!\n",
      "838 games have been completed!\n",
      "840 games have been completed!\n",
      "842 games have been completed!\n",
      "843 games have been completed!\n",
      "844 games have been completed!\n",
      "847 games have been completed!\n",
      "848 games have been completed!\n",
      "851 games have been completed!\n",
      "852 games have been completed!\n",
      "853 games have been completed!\n",
      "855 games have been completed!\n",
      "856 games have been completed!\n",
      "858 games have been completed!\n",
      "859 games have been completed!\n",
      "861 games have been completed!\n",
      "862 games have been completed!\n",
      "863 games have been completed!\n",
      "864 games have been completed!\n",
      "865 games have been completed!\n",
      "866 games have been completed!\n",
      "867 games have been completed!\n",
      "868 games have been completed!\n",
      "872 games have been completed!\n",
      "873 games have been completed!\n",
      "875 games have been completed!\n",
      "877 games have been completed!\n",
      "880 games have been completed!\n",
      "881 games have been completed!\n",
      "882 games have been completed!\n",
      "883 games have been completed!\n",
      "884 games have been completed!\n",
      "885 games have been completed!\n",
      "886 games have been completed!\n",
      "887 games have been completed!\n",
      "888 games have been completed!\n",
      "889 games have been completed!\n",
      "891 games have been completed!\n",
      "892 games have been completed!\n",
      "893 games have been completed!\n",
      "894 games have been completed!\n",
      "895 games have been completed!\n",
      "897 games have been completed!\n",
      "899 games have been completed!\n",
      "901 games have been completed!\n",
      "902 games have been completed!\n",
      "903 games have been completed!\n",
      "905 games have been completed!\n",
      "906 games have been completed!\n",
      "909 games have been completed!\n",
      "910 games have been completed!\n",
      "912 games have been completed!\n",
      "913 games have been completed!\n",
      "914 games have been completed!\n",
      "915 games have been completed!\n",
      "916 games have been completed!\n",
      "918 games have been completed!\n",
      "920 games have been completed!\n",
      "921 games have been completed!\n",
      "922 games have been completed!\n",
      "923 games have been completed!\n",
      "925 games have been completed!\n",
      "926 games have been completed!\n",
      "927 games have been completed!\n",
      "929 games have been completed!\n",
      "930 games have been completed!\n",
      "931 games have been completed!\n",
      "932 games have been completed!\n",
      "933 games have been completed!\n",
      "935 games have been completed!\n",
      "936 games have been completed!\n",
      "937 games have been completed!\n",
      "938 games have been completed!\n",
      "939 games have been completed!\n",
      "940 games have been completed!\n",
      "941 games have been completed!\n",
      "943 games have been completed!\n",
      "944 games have been completed!\n",
      "947 games have been completed!\n",
      "950 games have been completed!\n",
      "951 games have been completed!\n",
      "954 games have been completed!\n",
      "955 games have been completed!\n",
      "956 games have been completed!\n",
      "959 games have been completed!\n",
      "960 games have been completed!\n",
      "961 games have been completed!\n",
      "962 games have been completed!\n",
      "963 games have been completed!\n",
      "964 games have been completed!\n",
      "965 games have been completed!\n",
      "967 games have been completed!\n",
      "968 games have been completed!\n",
      "969 games have been completed!\n",
      "970 games have been completed!\n",
      "971 games have been completed!\n",
      "972 games have been completed!\n",
      "974 games have been completed!\n",
      "975 games have been completed!\n",
      "976 games have been completed!\n",
      "977 games have been completed!\n",
      "978 games have been completed!\n",
      "979 games have been completed!\n",
      "980 games have been completed!\n",
      "982 games have been completed!\n",
      "983 games have been completed!\n",
      "984 games have been completed!\n",
      "985 games have been completed!\n",
      "986 games have been completed!\n",
      "988 games have been completed!\n",
      "989 games have been completed!\n",
      "992 games have been completed!\n",
      "993 games have been completed!\n",
      "994 games have been completed!\n",
      "997 games have been completed!\n",
      "998 games have been completed!\n",
      "1000 games have been completed!\n",
      "1001 games have been completed!\n",
      "1003 games have been completed!\n",
      "1004 games have been completed!\n",
      "1005 games have been completed!\n",
      "1007 games have been completed!\n",
      "1009 games have been completed!\n",
      "1012 games have been completed!\n",
      "1013 games have been completed!\n",
      "1016 games have been completed!\n",
      "1017 games have been completed!\n",
      "1019 games have been completed!\n",
      "1020 games have been completed!\n",
      "1022 games have been completed!\n",
      "1023 games have been completed!\n",
      "1024 games have been completed!\n"
     ]
    }
   ],
   "source": [
    "for it in range(NUM_IT):\n",
    "    # create agent, provision games:\n",
    "    my_agent = Agent(\n",
    "        agent_id='1', # not relevant for a single machine:\n",
    "        network = my_network,\n",
    "        device = my_device,\n",
    "        num_trees = NUM_TREES, # number of in series trees to use:\n",
    "        target_games = TARGET_GAMES, # total number of games in the data set\n",
    "        selection_temperature = SELECTION_TEMP,\n",
    "        topn=TOPN, # only explore the top 5 best moves\n",
    "        randn=RANDN, # explore an additional 5 random moves\n",
    "        save_depth=SAVE_DEPTH, # for this, only save the final state and move\n",
    "        explore_steps_schedule=SCHEDULE,  \n",
    "        debug=False, \n",
    "    )\n",
    "\n",
    "    # run the games until target amount reached:\n",
    "    my_agent.run_games()\n",
    "\n",
    "    # save to timestamp location\n",
    "    save_string = datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M\")\n",
    "    filepath = os.path.join(Path.cwd(), 'saved_games', 'search_v1', f\"{save_string}.pkl\")\n",
    "    pickle.dump(my_agent.completed_games, open(filepath, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e0392a-a383-4ca5-99be-9f99f960fb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_agent.trees[0].root_node.game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef084069-538b-404f-900d-cb8e66e99520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ISSUE: trees are stepped after inference is assigned, but before a second\n",
    "# visit allows for attributes to be assigned and therefore children and actions\n",
    "# to be assigned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913d3c3e-7ba6-45d6-9af4-a8ea3571a966",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_agent.ready_trees[0].root_node.value_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b72916-fe7e-46f6-9581-b44733eb409f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _it, _tree in enumerate(my_agent.ready_trees):\n",
    "    action_argument = _tree.choose_action_argument()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec0582d-4e93-433a-8b36-a01d9a2c95bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "investigate_tree = copy.deepcopy(my_agent.ready_trees[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245e1c4e-fad2-4e74-a616-56e766108216",
   "metadata": {},
   "outputs": [],
   "source": [
    "investigate_tree.root_node.visit_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a111b3-9ef6-41a4-ab18-851092426509",
   "metadata": {},
   "outputs": [],
   "source": [
    "_it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43d2b0c-925d-4ff7-ad3d-1cbd735d75ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_agent._debug_leaf.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6d73d0-0374-43eb-8605-00e2efbd2c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_leaf = copy.deepcopy(my_agent._debug_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612c2bff-2e9e-482c-81c2-49c688737581",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_leaf.depth, copy_leaf.children, copy_leaf.possible_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3b0330-d422-4c06-8849-f9440b544ec0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68853a01-c81f-4a09-8763-231a22e61b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pplotter = PatternPlotter(copy_leaf.game)\n",
    "pplotter.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df8e4d8-a38a-4dc9-be9c-3a66a0a05612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %prun my_agent.run_games()\n",
    "my_agent.run_games()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9156dc92-776d-495f-acb1-965dccbba4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_string = datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M\")\n",
    "filepath = os.path.join(Path.cwd(), 'saved_games', f\"{save_string}.pkl\")\n",
    "pickle.dump(my_agent.completed_games, open(filepath, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a059a4-fbd5-417e-bd46-2d2d6bba995d",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_games = my_agent.completed_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c10e236-d95a-4d65-8a23-2fbebb3282be",
   "metadata": {},
   "outputs": [],
   "source": [
    "_lstrings = [\n",
    "    '2025_07_01_23_03',\n",
    "    '2025_07_01_23_23',\n",
    "            ]\n",
    "\n",
    "load_string = os.path.join(Path.cwd(), 'saved_games', _lstrings[0] +'.pkl')\n",
    "\n",
    "saved_games = pickle.load(open(load_string, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04efe062-2013-417c-b9d8-9ad5c8cedc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(saved_games[-1]), len(saved_games[0]), len(saved_games[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d432f6-9b56-4beb-888e-1810aaf58e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 10000\n",
    "_check = saved_games[1][ind]\n",
    "\n",
    "# _check = random.choice(saved_games[1])\n",
    "\n",
    "check_tensor = _check[0]\n",
    "check_visit_counts = _check[1]\n",
    "check_distance_from_terminal = _check[2]\n",
    "check_flipped = _check[3]\n",
    "check_nod_result = _check[4]\n",
    "\n",
    "# check_nod = _check[5]\n",
    "\n",
    "check_aug = StateAugmentor(check_tensor)\n",
    "reconstructed_game = check_aug.create_game_from_state()\n",
    "print(reconstructed_game._is_no_more_placing)\n",
    "reconstructed_game.set_is_no_more_placing()\n",
    "\n",
    "pplotter_1 = PatternPlotter(reconstructed_game)\n",
    "pplotter_1.plot()\n",
    "\n",
    "# pplotter_2 = PatternPlotter(game=check_nod.game)\n",
    "\n",
    "# pplotter_2.plot()\n",
    "check_tensor[-10:, 0, 0], check_nod_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8e45e4-d238-4109-ab21-50fbb19cdfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.2333 * 150, 0.333 * 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0fa0e5-30a1-4501-a01d-2e2170220691",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_game._possible_placing_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e633fa-b9a5-4287-965d-21d1537fce5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_actions = reconstructed_game.get_actions()\n",
    "for _act in _actions:\n",
    "    _cgame = copy.deepcopy(reconstructed_game)\n",
    "    _cgame.step(_act)\n",
    "    print(_act, _cgame.result, _cgame.calculate_score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81773d28-d69e-436e-822f-578d898d6405",
   "metadata": {},
   "outputs": [],
   "source": [
    "_game = copy.deepcopy(check_nod.game)\n",
    "pplotter = PatternPlotter(game=_game)\n",
    "pplotter.plot()\n",
    "_game.get_actions(), _game.calculate_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d899d467-2a3c-486e-a2fc-7003032b0222",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(saved_games[1].keys()))\n",
    "print(sorted(saved_games[0].keys()))\n",
    "print(sorted(saved_games[-1].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92e9c84-0477-48a1-9032-57db40b814ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_games[0][15] # list of a tuple of lists...\n",
    "# would be better if we instead just had a single list of tensors and single list of blah.\n",
    "# this way they are held together, in some sense, but I guess we want to zip them or something?\n",
    "\n",
    "# so what we want to see for the saved_games[win][number flipped] is a list of tuples.\n",
    "\n",
    "#how can we best go about doing that?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82729dd2-a57a-47a0-a4a6-64fe2d706d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "_draw = saved_games[0][15][0]\n",
    "_loss = saved_games[1][18][0]\n",
    "_win = saved_games[-1][3][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac9f57b-6f9c-4c8a-b416-b7f364ecaea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pplotter_loss = PatternPlotter(game_tensor = rand_win[0][0])\n",
    "pplotter_loss.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b0f9e5-42de-4853-b8bc-473169f940e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_check = _loss\n",
    "\n",
    "check_tensor = _check[0][0]\n",
    "check_root_node = _check[-1]\n",
    "check_node = _check[-2][0]\n",
    "\n",
    "pplotter_test = PatternPlotter(game_tensor=check_tensor)\n",
    "pplotter_2 = PatternPlotter(game=check_root_node.game)\n",
    "pplotter_3 = PatternPlotter(game=check_node.game)\n",
    "\n",
    "pplotter_test.plot()\n",
    "pplotter_2.plot()\n",
    "pplotter_3.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00ddffc-64fa-49df-8d4f-8ca5d590f5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ind in range(100):\n",
    "    _gam = saved_games[_ind]\n",
    "    pplotter = PatternPlotter(game_tensor=_gam[0][0])\n",
    "    pplotter.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcc2b6a-d54f-41fb-b9df-eb751c1238e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _it, _tree in enumerate(my_agent.trees):\n",
    "    print(_it)\n",
    "    ln = _tree.get_leaf_node()\n",
    "    nln = ln.expand()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20c0334-3033-4dde-b892-0c90ff388b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_tree = my_agent.trees[358]\n",
    "bad_nod = bad_tree.get_leaf_node()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc683bd-ab7d-4692-a67a-0c32418fef34",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_nod.game.active_orthogonal_groups, bad_nod.game.active_flipping_groups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39c4e9d-802f-4cda-82eb-86c6eafa9229",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_node = bad_nod.parent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564d413d-9d9d-428b-a596-46ba28c185de",
   "metadata": {},
   "outputs": [],
   "source": [
    "pplotter = PatternPlotter(bad_nod.game)\n",
    "pplotter.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48affc5-93d0-477c-8b6f-850508efc05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pplotter2 = PatternPlotter(parent_node.game)\n",
    "pplotter2.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107892c1-0512-4234-af43-6bc1f9c6f099",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bad_nod.parent_action_arg, parent_node.possible_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742403ed-c674-4b64-ab08-98ef807a0199",
   "metadata": {},
   "outputs": [],
   "source": [
    "from int_to_board import location_to_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f0fe70-4da9-4e49-ae57-1e83772a386b",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_node.game.is_action_terminal(44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ae96ef-6abe-40ca-a440-dbe59e34b436",
   "metadata": {},
   "outputs": [],
   "source": [
    "pgame = copy.deepcopy(parent_node.game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cb2cc5-f94c-4c5c-9987-9a1f15e42989",
   "metadata": {},
   "outputs": [],
   "source": [
    "action = 44\n",
    "removed_location = location_to_coordinates[action % 52]\n",
    "color = pgame.active_bowl_token if action < 52 else pgame.active_board[removed_location]\n",
    "print(removed_location, color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a50c931-061e-40ae-a75d-901b43d1db19",
   "metadata": {},
   "outputs": [],
   "source": [
    "pgame.passive_flipping_groups[5] - {removed_location}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12565b4-475a-431e-8b51-2efc95676bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "interesting_node = my_agent.completed_games[0][3][0]\n",
    "interesting_game = interesting_node.game\n",
    "# interesting_game.get_actions(), interesting_node.possible_actions \n",
    "print(interesting_game.active_orthogonal_groups)\n",
    "print(interesting_game.active_bowl_token)\n",
    "print(interesting_game.passive_bowl_token)\n",
    "print(interesting_node.winning_action_arguments, interesting_node.possible_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3dd0b9-d7a0-44f9-aaf2-31d85acb80d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "interesting_node.tensor_state[90:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb63196-9fbd-49fe-894a-11d581c54415",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_agent.completed_games[0][0][0][90:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c8df7f-f1a2-4a51-8c2d-aa725441b4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pplotter = PatternPlotter(interesting_game)\n",
    "pplotter.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ec41ba-c374-4147-962b-bd0c5b21e8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotting\n",
    "reload(plotting)\n",
    "from plotting import PatternPlotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc1c85c-5c77-413b-87e0-f6b3fe7604b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "wins, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea21927-d925-484f-b946-b5ac4c6143b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wins, losses = 0, 0\n",
    "for _game in my_agent.completed_games:\n",
    "    # nod = _game[3][0]\n",
    "    # print(np.where(_game[1][0]))\n",
    "    # print(nod.possible_actions, nod.child_visit_counts)\n",
    "    # print(nod.winning_action_arguments, nod.losing_action_arguments)\n",
    "    # print(nod.game.get_actions())\n",
    "    \n",
    "    # pltter = PatternPlotter(game_tensor=_game[0][0])\n",
    "    # pltter.plot()\n",
    "    \n",
    "    if _game[2][0] == 1:\n",
    "        wins += 1\n",
    "        \n",
    "    if _game[2][0] == -1:\n",
    "        losses += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fc88e3-46ba-4aa0-a733-0b755848d2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_game = Patterns()\n",
    "\n",
    "while True:\n",
    "    actions = a_game.get_actions()\n",
    "    if not actions:\n",
    "        break\n",
    "    action = random.choice(actions)\n",
    "    a_game.step(action)\n",
    "    if a_game.result is not None:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f21ff6e-bd68-4c12-8800-9068672fcb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "pplotter = PatternPlotter(a_game)\n",
    "pplotter.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f927c198-cb04-4687-8a42-abbb52a4954a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(a_game.flipped_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcddfb7-7b31-41e4-b83d-46e581292956",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_node = my_agent.completed_games[0][4][0]\n",
    "new_nod = game_node\n",
    "\n",
    "while game_node.parent:\n",
    "    pltter = PatternPlotter(new_nod.game)\n",
    "    pltter.plot()\n",
    "    new_nod = new_nod.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e795e0-5c95-4422-826f-63301f26b043",
   "metadata": {},
   "outputs": [],
   "source": [
    "nods = my_agent.completed_games[0][-1]\n",
    "nods[1].parent == nods[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d2bf6b-a3cb-46f6-90f0-e155c62cc6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from int_to_board import loci, locj\n",
    "\n",
    "def get_state_attributes(node) -> tuple:\n",
    "    \"\"\" return the active board, the active and passive orders and the active and passive bowl tokens\n",
    "    that would belong to this node.\n",
    "\n",
    "    tuple return is:\n",
    "    board, active_order, passive_order, active_token, passive_token\n",
    "    \"\"\"\n",
    "    # collect the game and parent action argument:\n",
    "    game = copy.deepcopy(node.parent.game)\n",
    "    action = node.parent.possible_actions[node.parent_action_arg]\n",
    "    print(node.parent.possible_actions)\n",
    "    print(node.parent_action_arg)\n",
    "\n",
    "    # always use passive board, as we will swap players from the parent:\n",
    "    board = torch.tensor(game.passive_board)\n",
    "\n",
    "    # active and passive reversed to represent the swap in players after action:\n",
    "    active_order = game.passive_color_order[:]\n",
    "    passive_order = game.active_color_order[:]\n",
    "    active_token = game.passive_bowl_token\n",
    "    passive_token = game.active_bowl_token\n",
    "\n",
    "    # if start of game:\n",
    "    if action >= 104:\n",
    "        active_token = (action + 1) % 2\n",
    "        passive_token = action % 2\n",
    "\n",
    "        return board, [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], active_token, passive_token\n",
    "\n",
    "    # remaining actions represent a change to the board state:\n",
    "    location = action % 52\n",
    "    print(location, action)\n",
    "    coords = loci[location], locj[location]\n",
    "    print(coords)\n",
    "    print(passive_token)\n",
    "\n",
    "    # passive board location -> active bowl token, as these will be added on to in update_locations()\n",
    "    if action < 52:\n",
    "        # + 12 to represent that the placed token belongs to the passive player, from the point of view of this\n",
    "        # node:\n",
    "        passive_token, board[coords] = board[coords].item(), passive_token + 12\n",
    "\n",
    "    # only the passive order can be updated...\n",
    "    if game.active_bowl_token not in game.active_color_groups:\n",
    "        passive_order[game.active_bowl_token] = game.active_placing_number\n",
    "\n",
    "    return board, active_order, passive_order, active_token, passive_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85397fda-0e2a-44f7-9ed2-2e0bac6f6fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _game in my_agent.completed_games:#game_index = 1\n",
    "    \n",
    "    # _game = my_agent.completed_games[game_index]\n",
    "    \n",
    "    node1 = _game[4][0]\n",
    "    node2 = _game[4][1]\n",
    "    \n",
    "    game_move_1 = _game[3][0]\n",
    "    game_move_2 = _game[3][1]\n",
    "    \n",
    "    tensor_move_1 = _game[0][0]\n",
    "    tensor_move_2 = _game[0][1]\n",
    "    \n",
    "    game_visit_counts_1 = _game[1][0]\n",
    "    game_visit_counts_2 = _game[1][1]\n",
    "    \n",
    "    plot1 = PatternPlotter(game=game_move_1)\n",
    "    plot2 = PatternPlotter(game=game_move_2)\n",
    "    \n",
    "    plot12 = PatternPlotter(game_tensor=tensor_move_1)\n",
    "    plot22 = PatternPlotter(game_tensor=tensor_move_2)\n",
    "    \n",
    "    # fsize = (7, 7)\n",
    "    # plot1.plot(fsize)\n",
    "    # plot12.plot(fsize)\n",
    "    \n",
    "    # plot2.plot(fsize)\n",
    "    # plot22.plot(fsize)\n",
    "    \n",
    "    # print(g1.get_actions(), my_agent.completed_games[-1][1][0])\n",
    "    # plot1.plot(fig_size=(7, 7))\n",
    "    # plot12.create_plotting_game_from_tensor_state(my_agent.completed_games[-1][0][0])\n",
    "    \n",
    "    # print(g2.get_actions(), my_agent.completed_games[-1][1][1])\n",
    "    # plot2.plot(fig_size=(7, 7))\n",
    "    \n",
    "    print(np.where(game_visit_counts_1), game_move_1.get_actions(), node1.possible_actions)\n",
    "    print(np.where(game_visit_counts_2), game_move_2.get_actions(), node2.possible_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c47bc2-59cf-497d-973c-29b225345ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "node1.possible_actions, node2.parent_action_arg, node2.parent.possible_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7dba52-ed3d-4adb-80b8-5a444966a04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "node2.parent == node1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1eb6cee-a38c-4a83-af50-09825d0fc346",
   "metadata": {},
   "outputs": [],
   "source": [
    "node1 == node2.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0eb401-cdaf-47b8-91b9-aef7f8f028b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(node2.parent.possible_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c266fe85-93c5-4fd8-a974-6a91c77b3a7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49ecd29-6527-4bb0-b53e-136745cdd579",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_state_attributes(node2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05cbf34-f106-45fe-915b-b37fd42f89e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_game = copy.deepcopy(my_agent.completed_games[game_index][3][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1abf8b-6331-4ec7-9499-a59f9aaca2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_game.active_board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d94964f-5993-4ffe-bd41-b4c9158fc4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_plotter.create_plotting_game_from_tensor_state(game[0][-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23b0eb3-b286-4b82-a6cd-a5f9e56e1be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.randint(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696d1856-50db-4324-874c-a319122df49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "make sure to return the ARGUMENT of the winning actions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330e8342-20b0-4a13-9fcd-c0735b704e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_agent.trees[0].choose_action_argument()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c599079-92e5-4303-8048-39ca6e55991a",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_agent.trees[0].root_node.possible_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da399a79-79d4-46d3-adb5-21561e88a83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(plotting)\n",
    "from plotting import PatternPlotter\n",
    "\n",
    "import augmentor\n",
    "reload(augmentor)\n",
    "from augmentor import Augmentor, StateAugmentor\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa3548f-e2e6-480c-adff-bff24d21bd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "ln = my_agent.trees[0].get_leaf_node()\n",
    "nod = ln.parent\n",
    "nod.create_tensor_state()\n",
    "\n",
    "pplotter = PatternPlotter(nod.game)\n",
    "pplotter2 = PatternPlotter(nod.game)\n",
    "pplotter2.create_plotting_game_from_tensor_state(nod.tensor_state)\n",
    "pplotter.plot()\n",
    "\n",
    "copy_nod = copy.deepcopy(nod)\n",
    "my_aug = StateAugmentor(copy_nod.tensor_state)\n",
    "my_aug.full_augment()\n",
    "\n",
    "pplotter3 = PatternPlotter(nod.game)\n",
    "pplotter3.create_plotting_game_from_tensor_state(copy_nod.tensor_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d8a283-509b-4d6f-90cb-dc01792db5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_required_steps(schedule, my_depth) -> None:\n",
    "    \"\"\" use the schedule to determine how many root node explores this node should have:\n",
    "\n",
    "    Schedule always starts with (0, X) to state that there are X required steps at depth 0\n",
    "\n",
    "    Then either there is no other tuple, in which case all root nodes explore for X, or there are\n",
    "    other schedules, and as soon as your depth is below the first entry, you take the previous\n",
    "    \"\"\"\n",
    "    curr_explore = schedule[0][1]\n",
    "    for _depth, _steps in schedule:\n",
    "        if my_depth < _depth:\n",
    "            break\n",
    "            \n",
    "        curr_explore = _steps\n",
    "        \n",
    "    return curr_explore\n",
    "\n",
    "schedule1 = [(0, 200), (5, 50), (10, 150)]\n",
    "schedule2 = [(0, 10)]\n",
    "\n",
    "d1 = 1\n",
    "d2 = 5\n",
    "d3 = 6\n",
    "d4 = 20\n",
    "\n",
    "r11 = determine_required_steps(schedule1, d1)\n",
    "r12 = determine_required_steps(schedule1, d2)\n",
    "r13 = determine_required_steps(schedule1, d3)\n",
    "r14 = determine_required_steps(schedule1, d4)\n",
    "\n",
    "r21 = determine_required_steps(schedule2, d1)\n",
    "r22 = determine_required_steps(schedule2, d2)\n",
    "r23 = determine_required_steps(schedule2, d3)\n",
    "r24 = determine_required_steps(schedule2, d4)\n",
    "\n",
    "print(r11, r12, r13, r14)\n",
    "print(r21, r22, r23, r24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59405c1f-5b7f-4743-855e-d969c6bd1049",
   "metadata": {},
   "outputs": [],
   "source": [
    "jim = np.array([1, 2, 3, 4])\n",
    "james = np.array([1, 2])\n",
    "\n",
    "random.choice(list(set(jim) - set(james)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511cfcc0-43aa-40ae-851b-9ccaec84dff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nod.tensor_state[0, 1, 0], ln.tensor_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ccbf51-bdf0-4349-8c5d-0c47d8559d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "board = np.zeros((3, 3))\n",
    "board[1, 1] = 1\n",
    "torch.nn.functional.one_hot(torch.tensor(board).long(), num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62abc3fb-5029-4ee2-b946-460bdee7b16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_tensor = torch.rand((3, 4))\n",
    "random_tensor = torch.zeros((3, 4), dtype=int)\n",
    "random_tensor[2, 0] = 1\n",
    "inds = torch.where(random_tensor[:, 0] == 1)\n",
    "inds[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fcd510-3ddf-460e-b1cd-b6778e8d8558",
   "metadata": {},
   "outputs": [],
   "source": [
    "jim = np.array([0, 1, 2])\n",
    "arr, = np.where(jim == 1)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac50723b-f566-483e-aab6-81ca6b2a1df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_board = np.random.rand(3, 4, 5)\n",
    "numpy_board = np.arange(0, 3 * 4 * 5).reshape((3, 4, 5))\n",
    "np.flip(numpy_board, axis=2), np.rot90(numpy_board, k=1, axes=(1, 2)), numpy_board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473a7213-722e-4164-aa90-2f28c9332d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ln = my_agent.trees[0].get_leaf_node()\n",
    "parent = ln.parent\n",
    "leaf_game = ln.game\n",
    "parent_game = parent.game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283c54d3-7639-479a-bf33-082d979e4dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_game.result, leaf_game.is_no_more_placing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6f10f3-6d68-43c8-8d0f-011452b86663",
   "metadata": {},
   "outputs": [],
   "source": [
    "from int_to_board import location_to_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee83ef17-aae9-4981-a7c1-278f27b0c55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "action = 6\n",
    "removed_location = location_to_coordinates[action % 52]\n",
    "color = parent_game.active_bowl_token if action < 52 else parent_game.active_board[removed_location]\n",
    "\n",
    "color, removed_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b7c5e6-db59-4287-8dde-a7655789425f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(parent_game.passive_orthogonal_groups[parent_game.passive_bowl_token]\n",
    "                               - parent_game.active_orthogonal_groups[parent_game.passive_bowl_token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccb9bca-009b-4837-ac67-72d78a9a6137",
   "metadata": {},
   "outputs": [],
   "source": [
    "pplotter = PatternPlotter(leaf_game)\n",
    "pplotter.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd206462-d487-4d39-9578-2eaa8c38237c",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_game.get_actions(), leaf_game.get_actions(), parent_game.is_no_more_placing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0315d59c-ead8-4ced-8aee-63144d5be5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pplotter = PatternPlotter(parent_game)\n",
    "pplotter.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81652733-39e8-46cd-9e77-764fb229445a",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_agent.trees[0].root_node.possible_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73170219-1a8b-43ac-ba36-4dbe4a00b74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "jim = [1, 2, 3, 4]\n",
    "james = jim[10:]\n",
    "random.shuffle(james)\n",
    "james[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c8f9bb-e361-4f44-b803-7cf476034533",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_node = my_agent.test_leaf\n",
    "parent = my_node.parent\n",
    "pg = parent.game\n",
    "\n",
    "pplotter = PatternPlotter(pg)\n",
    "pplotter.plot()\n",
    "\n",
    "parent.possible_actions, my_node.parent_action_arg\n",
    "parent_action = parent.possible_actions[my_node.parent_action_arg]\n",
    "parent_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dc5485-b368-4ab4-8404-297b9ba8e935",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent.possible_actions, parent.game.get_actions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f686ce46-d98f-49d8-b970-e4d07ef4adf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "27 in parent.game.get_actions()\n",
    "#, 15, 24, 28,  9, 44, 13, 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8ae3f5-e5cc-46d8-9898-b7aba9dc3917",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_node.game.passive_bowl_token, parent_node.game.active_bowl_token, parent_action\n",
    "from int_to_board import loci, locj\n",
    "\n",
    "coords = loci[parent_action], locj[parent_action]\n",
    "coords, parent_game.passive_board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125b45ff-d664-4996-ac0a-b7d2feca624d",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_node = my_agent.trees[0].get_leaf_node()\n",
    "parent_node = my_node.parent\n",
    "my_game = my_node.game\n",
    "parent_game = parent_node.game\n",
    "# pplotter = PatternPlotter(my_game)\n",
    "# pplotter.plot(fig_size=(6, 5))\n",
    "parent_plotter = PatternPlotter(parent_game)\n",
    "parent_plotter.plot(fig_size=(6, 5))\n",
    "parent_action = parent_node.possible_actions[my_node.parent_action_arg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f557a1f5-9bd5-482f-b29b-7650a3413527",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_node.possible_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc8eac8-8282-41f5-b424-511da2d3e8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_node.get_state_attributes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f962369-1f29-4ef1-aba0-a53f8b4f5c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_node.tensor_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb680a9b-3712-48cc-8ac2-311fd03bdbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_node.parent_action_arg, parent_node.possible_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5523ed-f666-461e-b39b-959949567360",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_node.create_tensor_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710bfcdf-70dd-4d6a-ae59-a93785d1faa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_game = Patterns(parent_node.game)\n",
    "copy_game.step(25)\n",
    "pplotter = PatternPlotter(copy_game)\n",
    "pplotter.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f4198d-e1af-41f2-9833-93128900f3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_node.game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64256a46-d375-41b9-bad6-c8424cf0123f",
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_actions = parent_node.game.get_actions()\n",
    "\n",
    "# restrict the full policy to legal actions, arg sort.\n",
    "restricted_policy = parent_node.full_policy[possible_actions]\n",
    "print(restricted_policy)\n",
    "\n",
    "# sort actions according to the policy prior:\n",
    "prior_sorted_actions = np.argsort(restricted_policy)\n",
    "print(prior_sorted_actions)\n",
    "\n",
    "# select the top n best, according to the breadth restriction:\n",
    "topn_actions = prior_sorted_actions[:parent_node.breadth_restriction]\n",
    "print(topn_actions)\n",
    "\n",
    "# supplement with up to m random additional actions\n",
    "remaining_actions = prior_sorted_actions[parent_node.breadth_restriction:]\n",
    "np.random.shuffle(remaining_actions)\n",
    "random_actions = remaining_actions[:parent_node.random_restriction]\n",
    "\n",
    "print(possible_actions, topn_actions, random_actions)\n",
    "# assign new actions as though these were the only legal ones from this position:\n",
    "parent_node.possible_actions = np.hstack([topn_actions, random_actions])\n",
    "\n",
    "# # first restrict policy vector to the *legal actions*:\n",
    "parent_node.policy_vector = parent_node.numpy_softmax(parent_node.full_policy[parent_node.possible_actions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4dd958-f43a-44b1-83f3-5813db81dc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_node.policy_vector, parent_node.possible_actions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f83b59-95b7-4c60-8c10-a19ee25a8a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_node.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dd5ec7-4db9-448b-90b6-6d7587bd72b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_node.possible_actions, parent_node.game.get_actions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8725fd47-027c-4058-8f88-bababc92ed82",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_node = my_agent.trees[0].get_leaf_node()\n",
    "parent_node = my_node.parent\n",
    "my_game = my_node.game\n",
    "parent_game = parent_node.game\n",
    "pplotter = PatternPlotter(my_game)\n",
    "pplotter.plot(fig_size=(6, 5))\n",
    "parent_plotter = PatternPlotter(parent_game)\n",
    "parent_plotter.plot(fig_size=(6, 5))\n",
    "parent_action = parent_node.possible_actions[my_node.parent_action_arg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d866e90d-61a1-41b9-a7c4-71f57fa041d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from int_to_board import location_to_coordinates, orthogonal_neighbors\n",
    "\n",
    "removed_location = location_to_coordinates[parent_action % 52]\n",
    "removed_orthogonal = orthogonal_neighbors[removed_location]\n",
    "set_removed_location = set(removed_location)\n",
    "color = parent_game.active_bowl_token if parent_action < 52 else parent_game.active_board[removed_location]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504f90b0-61cc-4ad2-913e-5d6fc2c4f0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "{[5, 4, 3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61280094-be66-4c7e-8475-ff03758ccfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the new game and the is terminal stuff:\n",
    "game = Patterns()\n",
    "\n",
    "while True:\n",
    "    actions = game.get_actions()\n",
    "    print(actions)\n",
    "    action = random.choice(actions)\n",
    "    print(action)\n",
    "    is_terminal, result = game.step(action)\n",
    "\n",
    "    if is_terminal:\n",
    "        break\n",
    "\n",
    "    pplotter = PatternPlotter(game)\n",
    "    pplotter.plot(fig_size=(7, 5))\n",
    "\n",
    "pplotter = PatternPlotter(game)\n",
    "pplotter.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a959bf8e-2e4b-48fd-8d5f-f44ffd22c974",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_node = my_agent.trees[6].get_leaf_node()\n",
    "paction = my_node.parent_action_arg\n",
    "\n",
    "parent_node = my_node.parent\n",
    "parent_game = parent_node.game\n",
    "pplotter = PatternPlotter(my_node.game)\n",
    "pplotter_parent = PatternPlotter(parent_game)\n",
    "pplotter.plot()\n",
    "pplotter_parent.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae0de35-9849-4e01-9aa5-531fa63feed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_game.passive_flipping_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d70f251-1d2c-4987-b252-8606cc9b56a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_node.possible_actions[paction]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5287d4a-6329-46f0-bbe0-c594893ed93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "action = 90\n",
    "from int_to_board import location_to_coordinates\n",
    "\n",
    "if action >= 104:\n",
    "    print('false')\n",
    "    \n",
    "removed_location = location_to_coordinates[action % 52]\n",
    "print(removed_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb0f56f-7939-4e19-a02a-0d866816bedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_game.is_no_more_placing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041a88df-6100-4ff5-ac46-3a646e1f1b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_removed_location = set(removed_location)\n",
    "color = parent_game.active_bowl_token if action < 52 else parent_game.active_board[removed_location]\n",
    "\n",
    "# Placing moves, flipping moves of same color, flipping moves of different colors:\n",
    "placing_locations = parent_game.passive_placing_groups[parent_game.passive_bowl_token]\n",
    "\n",
    "# unless there are no more placing moves allowed:\n",
    "if parent_game.is_no_more_placing:\n",
    "    placing_locations = set()\n",
    "\n",
    "same_color_flipping_locations = parent_game.passive_flipping_groups[color]\n",
    "\n",
    "different_color_flipping_locations = set(location_to_coordinates[_loc - 52] for _loc in parent_game.passive_flipping_actions)\n",
    "different_color_flipping_locations -= same_color_flipping_locations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c7f603-1374-416b-9a37-a5481e74c54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "jim = {1: [2, 3, 4], 2: [5, 6], 3: [7, 8, 9, 10]}\n",
    "jason = [_x for _key, _val in jim.items() for _x in _val if _key != 2]\n",
    "jason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc45d47-ee3d-4830-9302-5e2272849252",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# now determine how many of these are killed by the current action:\n",
    "removed_orthogonal = orthogonal_neighbors[removed_location]\n",
    "\n",
    "# take the removed location from each of the sets:\n",
    "placing_locations -= set_removed_location\n",
    "different_color_flipping_locations -= set_removed_location\n",
    "same_color_flipping_locations -= set_removed_location\n",
    "\n",
    "# remove the orthogonals of the location from the same color flipping moves and the placing moves IF\n",
    "# they share a color only:\n",
    "same_color_flipping_locations -= removed_orthogonal\n",
    "\n",
    "if color == self.passive_bowl_token:\n",
    "    placing_locations -= removed_orthogonal\n",
    "\n",
    "# if there will be a single move remaining, the game is not terminal:\n",
    "if len(placing_locations) + len(same_color_flipping_locations) + len(different_color_flipping_locations) > 0:\n",
    "    return False\n",
    "\n",
    "return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3fc24b-8e0e-40a5-bbe6-b7b0f1ed11a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104427ed-d498-4bd3-8c20-4fc3eb36fecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.profiler.profile(\n",
    "        activities=[\n",
    "            torch.profiler.ProfilerActivity.CPU,\n",
    "            torch.profiler.ProfilerActivity.CUDA,\n",
    "        ],\n",
    "        # schedule=torch.profiler.schedule(\n",
    "        #     wait=1, warmup=1, active=2, repeat=1, skip_first=1\n",
    "        # ),\n",
    "    ) as prof:\n",
    "        \n",
    "    my_agent.run_games()\n",
    "\n",
    "# prof.export_chrome_trace(f\"test_profiler.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357b4ec3-1691-4f93-bb0c-159c37b3ee69",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879d17db-5614-4150-92c7-f567678aacb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _game in my_agent.completed_games[9]:\n",
    "    print(_game.get_actions())\n",
    "    print(_game.calculate_score())\n",
    "    pplotter = PatternPlotter(_game, fig_size=(8, 5))\n",
    "    pplotter.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f555d76-bd95-4b9b-a161-62d0aca3f0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_agent.completed_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6846fe-92eb-4171-8e1d-4c9d76b564da",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tree = Tree()\n",
    "\n",
    "my_network = PatternsNet(\n",
    "    in_channels=102, # 102 for the number of state planes: 18 for tokens, 72 for order, 12 for bowl tokens\n",
    "    out_channels=64,\n",
    ").to(my_device)\n",
    "\n",
    "for it in range(200):\n",
    "    print(f\"--_-_-_-_-_-_-_-_-_-_-_\")\n",
    "    \n",
    "    # flow to leaf:\n",
    "    leaf_node = my_tree.get_leaf_node()\n",
    "\n",
    "    # choose a random child of the leaf node, if not first visit:\n",
    "    leaf_node = leaf_node.expand()\n",
    "\n",
    "    # collect the actions that lead here:\n",
    "    _climber = leaf_node\n",
    "    _act = []\n",
    "    \n",
    "    while _climber.parent:\n",
    "        _act.append(_climber.parent.possible_actions[_climber.parent_action_arg])\n",
    "        _climber = _climber.parent\n",
    "    \n",
    "    leaf_tensor = leaf_node.get_tensor_state()\n",
    "    tensor_stack = torch.stack([leaf_tensor])\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        value_stack, policy_stack = my_network(tensor_stack.float().to(my_device))\n",
    "    \n",
    "    value_stack = value_stack.cpu().numpy()[0]\n",
    "    policy_stack = policy_stack.cpu().numpy()[0]\n",
    "    leaf_node.value_score = value_stack\n",
    "    leaf_node.policy_vector = policy_stack[leaf_node.possible_actions]\n",
    "    my_tree.back_propagate(leaf_node)\n",
    "\n",
    "    # plot the leaf node, the root node, etc:\n",
    "    print(f\"Root Node:\")\n",
    "    root_plotter = PatternPlotter(my_tree.root_node.game, fig_size=(7, 4))\n",
    "    root_plotter.plot()\n",
    "\n",
    "    print(f\"Leaf Node:\")\n",
    "    leaf_plotter = PatternPlotter(leaf_node.game, fig_size=(7, 4))\n",
    "    leaf_plotter.plot()\n",
    "    \n",
    "    print(f\"\\nActions that lead here: {_act[::-1]}\")\n",
    "    print(f\"\\nThe active color order: {leaf_node.game.active_color_order}\")\n",
    "    print(f\"\\nThe passive color order: {leaf_node.game.passive_color_order}\")\n",
    "    print(f\"--_-_-_-_-_-_-_-_-_-_-_\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7f9ce8-b24c-48b5-be52-0a8cd9d63bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = np.zeros((2, 2), dtype=int)\n",
    "a2 = np.array(a1)\n",
    "a1[0, 0] = 4\n",
    "a1[0, 1] += 2\n",
    "a2[1, 0] -= 5\n",
    "\n",
    "a1, a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b544d15-463e-4b65-9a37-3d371410e11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = {'a': {1, 2, 3}}\n",
    "a2 = dict(a1)\n",
    "a1['b'] = [4, 5]\n",
    "a1['a'].append(9)\n",
    "a2['a'].append(10)\n",
    "a1, a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd48f26e-28ff-49a1-be50-316facce13a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {'a': [2, 3], 'b': [4, 5]}\n",
    "{_key: list(_val) for _key, _val in my_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4059f64-0a9f-4227-8e02-49ac81a50d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class class_checker:\n",
    "    def __init__(self, clone_class=None):\n",
    "        self.numpy_array = np.array([[1, 2, 3]])\n",
    "        self.list = [[4, 5, 6]]\n",
    "        self.val = 10\n",
    "        self.bool = True\n",
    "        self.set = {7, 8, 9}\n",
    "        self.dict = {'a': 1, 'b': 2, 'c': 3}\n",
    "\n",
    "        if clone_class is not None:\n",
    "            self.clone(clone_class)\n",
    "\n",
    "    def clone(self, another_class):\n",
    "        self.numpy_array = np.array(another_class.numpy_array)\n",
    "        self.list = another_class.list[:]\n",
    "        self.val = another_class.val\n",
    "        self.bool = another_class.bool\n",
    "        self.set = set(another_class.set)\n",
    "        self.dict = dict(another_class.dict)\n",
    "\n",
    "    def print_attributes(self):\n",
    "        print(self.numpy_array)\n",
    "        print(self.list)\n",
    "        print(self.val)\n",
    "        print(self.bool)\n",
    "        print(self.set)\n",
    "        print(self.dict)\n",
    "        \n",
    "\n",
    "class1 = class_checker()\n",
    "class2 = class_checker(class1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8fd252-f484-434a-ba3f-7cab4113b789",
   "metadata": {},
   "outputs": [],
   "source": [
    "class1.numpy_array[0] *= 10\n",
    "class2.numpy_array[1] *= 100\n",
    "\n",
    "class1.list[0] *= 10\n",
    "class2.list[1] *= 100\n",
    "\n",
    "class1.val +=5\n",
    "class2.val -= 50\n",
    "\n",
    "class1.bool = True\n",
    "class2.bool = False\n",
    "\n",
    "class1.set.add(50)\n",
    "class2.set.remove(7)\n",
    "\n",
    "class1.dict[50] = 100\n",
    "class2.dict['a'] = -1\n",
    "\n",
    "class1.print_attributes()\n",
    "print()\n",
    "class2.print_attributes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851fc800-2971-4a89-a629-7918e94cdb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "jon = np.array([1, 2, 3])\n",
    "jim = jon[1]\n",
    "jon[1] *= 10\n",
    "jim *= 100\n",
    "jim, jon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ec5c66-ec64-4335-966a-637b2b180122",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = [1, 2, 3]\n",
    "a2 = a1[:]\n",
    "a1[0] *= 10\n",
    "a2[1] *= 100\n",
    "\n",
    "a1, a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d795a7d0-db6a-4de5-bbdd-ec0ce7b44981",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tree = Tree()\n",
    "\n",
    "my_network = PatternsNet(\n",
    "    in_channels=102, # 102 for the number of state planes: 18 for tokens, 72 for order, 12 for bowl tokens\n",
    "    out_channels=64,\n",
    ").to(my_device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8115ab-4ebc-499a-a70d-b59d04b9d3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "# flow to leaf:\n",
    "leaf_node = my_tree.get_leaf_node()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bb0275-4627-4cce-b0e6-bc4f96b46d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_node = leaf_node.expand()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab4e1b2-b276-4e7c-a444-b7297af8e740",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_node.game.turn_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9420cadd-af66-4826-9d77-20f97c1dba39",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_node.value_score, leaf_node.policy_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4c1559-b967-41f3-90f7-c7db58449cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_game = leaf_node.game\n",
    "root_game =  my_tree.root_node.game\n",
    "\n",
    "root_game.active_color_groups is leaf_game.active_color_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ada4913-141f-4606-a686-5ea035c5aa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "leaf_tensor = leaf_node.get_tensor_state()\n",
    "tensor_stack = torch.stack([leaf_tensor])\n",
    "\n",
    "with torch.inference_mode():\n",
    "    value_stack, policy_stack = my_network(tensor_stack.float().to(my_device))\n",
    "\n",
    "value_stack = value_stack.cpu().numpy()[0]\n",
    "policy_stack = policy_stack.cpu().numpy()[0]\n",
    "leaf_node.value_score = value_stack\n",
    "leaf_node.policy_vector = policy_stack[leaf_node.possible_actions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2226f92-7e57-4d1a-8c1a-c60fe99e754c",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tree.back_propagate(leaf_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbafac9d-b4a2-45da-998e-38b97dafbe94",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([np.inf] * 10, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7eec64a-0c56-47b2-87a7-fae8151be949",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tree.root_node.game.turn_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93cbe2e-564b-4185-9e12-2d88072d9a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# choose a random child of the leaf node, if not first visit:\n",
    "leaf_node = leaf_node.expand()\n",
    "\n",
    "# collect the actions that lead here:\n",
    "_climber = leaf_node\n",
    "_act = []\n",
    "\n",
    "while _climber.parent:\n",
    "    _act.append(_climber.parent.possible_actions[_climber.parent_action_arg])\n",
    "    _climber = _climber.parent\n",
    "\n",
    "leaf_tensor = leaf_node.get_tensor_state()\n",
    "tensor_stack = torch.stack([leaf_tensor])\n",
    "\n",
    "with torch.inference_mode():\n",
    "    value_stack, policy_stack = my_network(tensor_stack.float().to(my_device))\n",
    "\n",
    "value_stack = value_stack.cpu().numpy()[0]\n",
    "policy_stack = policy_stack.cpu().numpy()[0]\n",
    "leaf_node.value_score = value_stack\n",
    "leaf_node.policy_vector = policy_stack[leaf_node.possible_actions]\n",
    "my_tree.back_propagate(leaf_node)\n",
    "\n",
    "# plot the leaf node, the root node, etc:\n",
    "print(f\"Root Node:\")\n",
    "root_plotter = PatternPlotter(my_tree.root_node.game, fig_size=(7, 4))\n",
    "root_plotter.plot()\n",
    "\n",
    "print(f\"Leaf Node:\")\n",
    "leaf_plotter = PatternPlotter(leaf_node.game, fig_size=(7, 4))\n",
    "leaf_plotter.plot()\n",
    "\n",
    "\n",
    "print(f\"\\nActions that lead here: {_act[::-1]}\")\n",
    "print(f\"\\nThe active color order: {leaf_node.game.active_color_order}\")\n",
    "print(f\"\\nThe passive color order: {leaf_node.game.passive_color_order}\")\n",
    "print(f\"--_-_-_-_-_-_-_-_-_-_-_\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7539cf-d966-44c6-b517-a72a5ebe1042",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tree.root_node.children, my_tree.root_node.visit_count, my_tree.root_node.possible_actions, my_tree.root_node.value_score, my_tree.root_node.policy_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c069d43e-76de-48f5-a56d-2326821145e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "jim = {1:2, 2:3, 3:4}\n",
    "james = dict(jim)\n",
    "jim[4] = 5\n",
    "james[5] = 4\n",
    "jim, james"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0316f8-9fb0-42dc-a5e8-576afa7e82e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_node.game.active_board, leaf_node.game.passive_board, leaf_node.parent_action_arg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22495b1-f709-4a55-b63f-97aea1237f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_node.parent.game.active_board, leaf_node.parent.game.passive_board, leaf_node.parent.possible_actions[32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e71b10-97ac-4378-b528-81c7be2a5d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_node.parent.game.active_color_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed582e2-ac47-4a54-a3ef-8b3d96d47580",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_node.parent.parent.parent.game.active_color_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82db2f77-165f-4268-a390-cdd19446d951",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_node.game.active_bowl_token, leaf_node.game.active_color_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dc8e46-78ec-4f68-8979-3db22eb4f53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_network = PatternsNet(\n",
    "    in_channels=102, # 102 for the number of state planes: 18 for tokens, 72 for order, 12 for bowl tokens\n",
    "    out_channels=64,\n",
    ")\n",
    "\n",
    "my_agent = Agent(\n",
    "    agent_id='1', \n",
    "    network = my_network,\n",
    "    device = my_device,\n",
    "    num_trees = 1, \n",
    "    explore_steps=100, \n",
    "    target_games=1,\n",
    "    selection_temperature=1.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4139539c-3a2c-4d15-bb14-08cd9078cb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_agent.trees[0].root_node.value_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968dc6bc-37ab-47b1-be92-c04c61ba74a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_agent.run_games()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f6f78d-0bd5-4195-9a80-de353cacf8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_patterns = Patterns()\n",
    "still_placing = True\n",
    "\n",
    "while True:\n",
    "    print(f\"Turn {my_patterns.turn_number}, for Player {my_patterns.player + 1}\")\n",
    "    print(f\"Score is currently:\")\n",
    "    active_score, passive_score = my_patterns.calculate_score()\n",
    "    \n",
    "    p1_score = active_score if my_patterns.player == 0 else passive_score\n",
    "    p2_score = active_score if my_patterns.player == 1 else passive_score\n",
    "    \n",
    "    print(f\"Player 1: {p1_score} -- {p2_score}: Player 2\")\n",
    "    \n",
    "    actions = my_patterns.get_actions() \n",
    "    print(f\"Available actions are: \\n{actions}\")\n",
    "    \n",
    "    if my_patterns.is_no_more_placing is True and still_placing is True:\n",
    "        still_placing = False\n",
    "        print(f\"###########################\")\n",
    "        print(f\"ALERT: no more placing moves from now on!\")\n",
    "        print(f\"###########################\")\n",
    "        \n",
    "    action = random.choice(actions)\n",
    "    print(f\"action taken is: {action}\")\n",
    "    is_terminal, _result = my_patterns.step(action)\n",
    "\n",
    "    if is_terminal:\n",
    "        break\n",
    "        \n",
    "    for _col in range(6):\n",
    "        if (my_patterns.active_color_order[_col] > 0) or (my_patterns.passive_color_order[_col] > 0):\n",
    "            print(f\"Color: {_col}\")\n",
    "            print(f\"Active flipping groups: {my_patterns.active_flipping_groups[_col]}\")\n",
    "            print(f\"Active placing groups: {my_patterns.active_placing_groups[_col]}\")\n",
    "            print(f\"Passive flipping groups: {my_patterns.passive_flipping_groups[_col]}\")\n",
    "            print(f\"Passive placing groups: {my_patterns.passive_placing_groups[_col]}\\n\")\n",
    "            \n",
    "    pattern_plotter = PatternPlotter(my_patterns, fig_size=(10, 7.5))\n",
    "    pattern_plotter.populate_board()\n",
    "\n",
    "print(f\"Game finished! Result is: {_result}\")\n",
    "\n",
    "pattern_plotter.populate_board()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb91b1e1-dfc3-49e1-8732-e75921764742",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print(my_patterns.player, my_patterns.active_board, my_patterns.active_bowl_token, )\n",
    "\n",
    "actions = my_patterns.get_actions()\n",
    "\n",
    "print(f\"Available actions are: {actions}\\n\")\n",
    "\n",
    "action = random.choice(actions)\n",
    "\n",
    "print(f\"action taken is: {action}\\n\")\n",
    "\n",
    "my_patterns.step(action)\n",
    "\n",
    "print(my_patterns.player, my_patterns.active_board, my_patterns.active_bowl_token)\n",
    "\n",
    "pattern_plotter = PatternPlotter(my_patterns, fig_size=(10, 7.5))\n",
    "pattern_plotter.populate_board()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55b0a81-e778-4f66-ac8b-3db0f90d2de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_random_patterns(num_iterations: int) -> None:\n",
    "    \"\"\" play a set number of random games\n",
    "    \"\"\"\n",
    "    num_turns = [0] * num_iterations\n",
    "    \n",
    "    for it in range(num_iterations):\n",
    "        patterns_game = Patterns()\n",
    "\n",
    "        while True:\n",
    "            actions = patterns_game.get_actions()\n",
    "            action = random.choice(actions)\n",
    "            is_terminal, result = patterns_game.step(action)\n",
    "            \n",
    "            if is_terminal:\n",
    "                break\n",
    "        num_turns[it] = patterns_game.turn_number\n",
    "\n",
    "    return num_turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b0e435-c671-46fb-a54e-d41590233a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "_res = play_random_patterns(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacef363-fb98-4505-a81e-2d1f0bccae19",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(_res) / 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1b910f-c435-44e3-8601-4c28e5d78bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len({1, 2, 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa26f953-4cab-4522-9952-6ea551137206",
   "metadata": {},
   "outputs": [],
   "source": [
    "%prun play_random_patterns(10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7546070-969d-4f29-a9ef-b468d6b104c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_set_minus(num_it):\n",
    "    my_dict = {_num: set(range(100)) for _num in range(6)}\n",
    "\n",
    "    for it in range(10000):\n",
    "        for _col in range(6):\n",
    "            my_dict[_col] -= {11}\n",
    "            \n",
    "def test_set_minus_2(num_it):\n",
    "    my_dict = {_num: set(range(100)) for _num in range(6)}\n",
    "\n",
    "    for it in range(10000):\n",
    "        for _col in range(6):\n",
    "            my_dict[_col] -= {11}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e766c4a2-f353-4bee-82e9-d1f9eed524ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%prun test_set_minus(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3a4128-49c6-4c18-888e-1d8f25524221",
   "metadata": {},
   "outputs": [],
   "source": [
    "%prun test_set_minus_2(100000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751bcde6-ec29-4a12-bf93-c83ee8628733",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import patches\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "token_center = (0.0, 0.0)\n",
    "outrad = 0.35\n",
    "inrad = 0.28\n",
    "num_points = 7\n",
    "arc = 2. * np.pi / num_points\n",
    "\n",
    "patch_coords_1 = [\n",
    "    [token_center[0] + outrad * np.cos(arc * _it),\n",
    "     token_center[1] + outrad * np.sin(arc * _it)]\n",
    "    for _it in range(num_points)\n",
    "]\n",
    "                \n",
    "patch_coords_2 = [\n",
    "    [token_center[0] + inrad * np.cos((arc / 2) + arc * _it),\n",
    "     token_center[1] + inrad * np.sin((arc / 2) + arc * _it)]\n",
    "    for _it in range(num_points)\n",
    "]\n",
    "\n",
    "patch_coords = []\n",
    "for p1, p2 in zip(patch_coords_1, patch_coords_2):\n",
    "    patch_coords.append(p1)\n",
    "    patch_coords.append(p2)\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "ax.add_patch(patches.Polygon(patch_coords, facecolor='red', edgecolor='black', linewidth=0.5))\n",
    "# ax.add_patch(patches.Polygon(patch_coords_1))\n",
    "# ax.add_patch(patches.Polygon(patch_coords_2))\n",
    "\n",
    "ax.set_xlim([-2., 2.])\n",
    "ax.set_ylim([-2., 2.])\n",
    "ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6a7ec3-dec3-4914-8e8f-5ef60755666a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9acf99e-76a3-4c5e-846c-0963a55a03d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BoardInitNet(nn.Module):\n",
    "    \"\"\" initial CNN processing of the board representation:\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 in_channels: int = 3,\n",
    "                 out_channels: int = 64,\n",
    "                 ) -> None:\n",
    "        super(BoardInitNet, self).__init__()\n",
    "\n",
    "        self.init = nn.Sequential(\n",
    "            # Gather all \"local\" information for each board spot (including stuff on top)\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.init(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58bbc5d-0ae1-44ac-b2ae-dd43ef5ee25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_net = BoardInitNet()\n",
    "input_tensor = torch.tensor(np.random.rand(1, 3, 8, 8)).float()\n",
    "my_net(input_tensor).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6941914b-9a5c-42c2-9292-5181fa2f2345",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_patterns.active_board\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dafd72b-c0aa-40fd-9131-bb73ba39447d",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_one_hot = torch.nn.functional.one_hot(torch.tensor(my_patterns.active_board).long(), num_classes=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6aabaa9-c1f4-42ed-aada-c41b1ca46016",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.functional.one_hot(torch.tensor(my_patterns.active_color_order).long() - 1, num_classes=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1bfad8-eb39-4e4c-a9ff-fcd4355aac06",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tens = torch.empty((8, 8, 36), dtype=bool)\n",
    "for _it, _order in enumerate(my_patterns.active_color_order):\n",
    "    my_tens[:, :, _it * 6 + _order] = 1\n",
    "\n",
    "my_tens.int().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0135000e-0afa-4784-96e4-03f51c344957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the board is just a one hot encoded version of the numpy board:\n",
    "board_tensor = torch.nn.functional.one_hot(torch.tensor(my_patterns.active_board).long(), num_classes=18)\n",
    "\n",
    "# 36 channels for each player for color group: order mapping:\n",
    "order_tensor = torch.empty((8, 8, 72), dtype=bool)\n",
    "for _it, (active_order, passive_order) in enumerate(zip(my_patterns.active_color_order, my_patterns.passive_color_order)):\n",
    "    order_tensor[:, :, _it * 6 + active_order] = 1\n",
    "    order_tensor[:, :, 36 + _it * 6 + passive_order] = 1\n",
    "    \n",
    "# bowl tokens:\n",
    "bowl_tensor = torch.empty((8, 8, 12), dtype=bool)\n",
    "bowl_tensor[:, :, my_patterns.active_bowl_token] = 1\n",
    "bowl_tensor[:, :, 6 + my_patterns.passive_bowl_token] = 1\n",
    "\n",
    "newtens =  torch.cat([board_tensor, order_tensor, bowl_tensor], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87ed713-2b59-4873-aa14-86f1801308bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "newtens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d72cfe-582c-4065-8cb1-aa28519c89bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "newtens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a687aed-1908-4245-a155-0a1fbffb90d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "72 + 18 + 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ac3c74-e51e-46f4-9818-f31c6541d596",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Value and Policy Neural Networks defined in PyTorch for use in the MCTS algorithm:\n",
    "\n",
    "State input is 8x8x102, which completely describes the current markov state.\n",
    "\n",
    "Note that if we ever move to using a transformer, it may not be necessary to continue storing the state in this way\n",
    "\n",
    "We create a CNN for the board, and MLPs for the other states.\n",
    "\n",
    "We want to munge the conv net on the board state and the state vectors early on...\n",
    "\n",
    "For now, we do all the CNN resnet stuff, followed by the MLP fully connected layers\n",
    "to blend the state with the image.\n",
    "\"\"\"\n",
    "import torch\n",
    "from torch import nn\n",
    "import math\n",
    "\n",
    "\n",
    "class PatternsNet(nn.Module):\n",
    "    \"\"\" Take in the initial munging of the board and player states, and perform standard resnet\n",
    "    fun on it:\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 in_channels: int = 102,\n",
    "                 out_channels: int = 64,\n",
    "                 ) -> None:\n",
    "        \"\"\" 102 in channels for patterns. 18 for color and player, 72 for color group order, 12 for bowl tokens.\n",
    "         \"\"\"\n",
    "        super(PatternsNet, self).__init__()\n",
    "\n",
    "        # initial processing layer: output size (samples, out_channels, 8, 8)\n",
    "        self.input_layer = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            # nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "\n",
    "        # Downsampling layers:\n",
    "        self.down1 = ResidualLayer(in_channels=out_channels, stride=2)\n",
    "        out_channels *= 2\n",
    "        self.down2 = ResidualLayer(in_channels=out_channels, stride=2)\n",
    "        out_channels *= 2\n",
    "\n",
    "        # Standard resnet layers:\n",
    "        self.standard1 = ResidualLayer(in_channels=out_channels, stride=1)\n",
    "        self.standard2 = ResidualLayer(in_channels=out_channels, stride=1)\n",
    "\n",
    "        # different heads:\n",
    "        self.twoheadlayer = TwoHeadNet(in_channels=out_channels,\n",
    "                                       value_out_channels=out_channels // 16,\n",
    "                                       policy_out_channels=out_channels // 4,\n",
    "                                       action_space=(106,))\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\" pass the input through the initial conv layer, expanding input channels to the number\n",
    "        of filters required, before passing through the residual blocks \"\"\"\n",
    "        x = self.input_layer(x)\n",
    "        x = self.down2(self.down1(x))\n",
    "        x = self.standard2(self.standard1(x))\n",
    "\n",
    "        return self.twoheadlayer(x)\n",
    "\n",
    "\n",
    "class TwoHeadNet(nn.Module):\n",
    "    \"\"\" Two different heads, attached to resnet backbone:\n",
    "\n",
    "    One head addresses the policy prediction (with action-space number of neurons)\n",
    "    one head addresses the value prediction (with a single neuron output, scaled to -1, 1\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 value_out_channels: int,\n",
    "                 policy_out_channels: int,\n",
    "                 action_space: tuple = (106,)) -> None:\n",
    "        super(TwoHeadNet, self).__init__()\n",
    "        self.action_space = action_space\n",
    "\n",
    "        # output is float between -1 and 1 estimating board state\n",
    "        self.value_head = nn.Sequential(\n",
    "            # final bespoke convolutional layer for value:\n",
    "            nn.Conv2d(in_channels, value_out_channels, kernel_size=3, padding=1, stride=1),# bias=False),\n",
    "            nn.BatchNorm2d(value_out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d(output_size=(1, 1)),\n",
    "            # squash to flat:\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=value_out_channels, out_features=1),\n",
    "            # squish to between -1 and 1 to estimate the result of the game:\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "        # output is logits for softmax to give distribution over action space\n",
    "        self.policy_head = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, policy_out_channels, kernel_size=3, padding=1, stride=1),# bias=False),\n",
    "            nn.BatchNorm2d(policy_out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d(output_size=(1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=policy_out_channels, out_features=math.prod(action_space)),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\" produce both outputs \"\"\"\n",
    "        value_x = self.value_head(x)\n",
    "        policy_x = self.policy_head(x).view((-1, *self.action_space))\n",
    "\n",
    "        return value_x, policy_x\n",
    "\n",
    "\n",
    "class ResidualLayer(nn.Module):\n",
    "    \"\"\" Stick two residual basic blocks together, apply down-sampling as required:\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 in_channels: int = 128,\n",
    "                 stride: int = 1) -> None:\n",
    "        super(ResidualLayer, self).__init__()\n",
    "\n",
    "        # The first block can be a down-sampling layer:\n",
    "        self.basic_block_1 = ResidualBlock(in_channels=in_channels, stride=stride)\n",
    "        self.basic_block_2 = ResidualBlock(in_channels=in_channels * stride, stride=1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\" basic_block_1 will return x + conv(x)\n",
    "        \"\"\"\n",
    "        x1 = self.basic_block_1(x)\n",
    "        return self.basic_block_2(x1)\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\" A residual block of a resnet.\n",
    "\n",
    "    Note that channels in and out are assumed equal, to allow for addition with manipulation.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 stride: int = 1) -> None:\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        self.is_downsample = True if stride != 1 else False\n",
    "\n",
    "        out_channels = stride * in_channels\n",
    "\n",
    "        # first layer can be downsample:\n",
    "        self.conv_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv_2 = nn.Sequential(\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "\n",
    "        # if downsampling, also downsample the residual for consistent tensor size:\n",
    "        if self.is_downsample:\n",
    "            # skip block needs a 1x1 conv to increase in channels:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\" conv block applied to x, with skip connection to allow for robust residual training \"\"\"\n",
    "        residual = x if not self.is_downsample else self.downsample(x)\n",
    "        return self.relu(residual + self.conv_2(self.conv_1(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5877b17-54ee-43bf-ad83-e673c3fa8a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tensor_state(game) -> torch.Tensor:\n",
    "    \"\"\" Use the game state to form a torch tensor that can be used to eval the position\n",
    "\n",
    "    Currently, the history is not included, but it might be in the future.\n",
    "\n",
    "    The tensor state is 8 x 8 x (6x3 + 6x6 + 6x6 + 2x6) binary tensor.\n",
    "\n",
    "    The first 6x3 planes represent the board itself, with planes 0-5 denoting the presence of an unflipped token\n",
    "    of that color, 6-11 representing flipped for active player of that color, and 12-17 flipped for passive player.\n",
    "\n",
    "    This matches the numpy array, one-hot-encoded.\n",
    "\n",
    "    The next 2x6x6 planes represent the color group order taken, for each player.\n",
    "\n",
    "    In particular, these planes are constant 1 or constant 0.\n",
    "    Planes 0-5 represent the order at which color 0 was taken for the active player\n",
    "    Planes 6-11 represent the order at which color 1 was taken for the active player etc.\n",
    "\n",
    "    Planes 36 - 41 represent the order at which color 0 was taken for the passive player.\n",
    "    Planes 42 - 47 represent the order at which color 1 was taken for the passive player etc.\n",
    "\n",
    "    Finally, the final 12 planes represent the color of the bowl token for the active player (0-5) and the\n",
    "    passive player (6-11).\n",
    "    \"\"\"\n",
    "    # the board is just a one hot encoded version of the numpy board:\n",
    "    board_tensor = torch.nn.functional.one_hot(torch.tensor(game.active_board).long(), num_classes=18)\n",
    "\n",
    "    # 36 channels for each player for color group: order mapping:\n",
    "    order_tensor = torch.zeros((8, 8, 72), dtype=bool)\n",
    "    for _it, (active_order, passive_order) in enumerate(zip(game.active_color_order, game.passive_color_order)):\n",
    "        if active_order > 0:\n",
    "            order_tensor[:, :, _it * 6 + active_order - 1] = 1\n",
    "\n",
    "        if passive_order > 0:\n",
    "            order_tensor[:, :, 36 + _it * 6 + passive_order - 1] = 1\n",
    "\n",
    "    # bowl tokens:\n",
    "    bowl_tensor = torch.zeros((8, 8, 12), dtype=bool)\n",
    "    bowl_tensor[:, :, game.active_bowl_token] = 1\n",
    "    bowl_tensor[:, :, 6 + game.passive_bowl_token] = 1\n",
    "    concat_tensor = torch.cat([board_tensor, order_tensor, bowl_tensor], dim=-1)\n",
    "\n",
    "    return concat_tensor.permute(2, 0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1360512-7d92-45e8-a69d-cd21cd34699e",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tens = get_tensor_state(my_patterns)\n",
    "device = torch.device('cuda')\n",
    "pnet = PatternsNet()\n",
    "pnet.to(device)\n",
    "my_tens = my_tens.to(device).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d568d10d-507a-4a45-b879-3c2ac312c27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "out1 = pnet.input_layer(my_tens[None])\n",
    "out2 = pnet.down1(out1)\n",
    "out3 = pnet.down2(out2)\n",
    "out4 = pnet.standard1(out3)\n",
    "out5 = pnet.standard2(out4)\n",
    "out6 = pnet.twoheadlayer(out5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17333f9d-c737-4bf8-b1fb-f9a86cca7815",
   "metadata": {},
   "outputs": [],
   "source": [
    "out1.shape, out2.shape, out3.shape, out4.shape, out5.shape, out6[0].shape, out6[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda6d84d-0fc5-4fbe-a7f0-70911441f85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the board is just a one hot encoded version of the numpy board:\n",
    "board_tensor = torch.nn.functional.one_hot(torch.tensor(my_patterns.active_board).long(), num_classes=18)\n",
    "\n",
    "# 36 channels for each player for color group: order mapping:\n",
    "order_tensor = torch.zeros((8, 8, 72), dtype=bool)\n",
    "for _it, (active_order, passive_order) in enumerate(zip(my_patterns.active_color_order, my_patterns.passive_color_order)):\n",
    "    if active_order > 0:\n",
    "        order_tensor[:, :, _it * 6 + active_order - 1] = 1\n",
    "\n",
    "    if passive_order > 0:\n",
    "        order_tensor[:, :, 36 + _it * 6 + passive_order - 1] = 1\n",
    "\n",
    "# bowl tokens:\n",
    "bowl_tensor = torch.zeros((8, 8, 12), dtype=bool)\n",
    "bowl_tensor[:, :, my_patterns.active_bowl_token] = 1\n",
    "bowl_tensor[:, :, 6 + my_patterns.passive_bowl_token] = 1\n",
    "\n",
    "concat_tensor = torch.cat([board_tensor, order_tensor, bowl_tensor], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a0cd6b-6374-4949-ad76-c5027f4360d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_patterns.active_bowl_token, my_patterns.passive_bowl_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28a2253-1183-439d-8247-0e3a6108eea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bowl_tensor[:, :, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6835e0-7814-4008-8772-c257e8d476da",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tensor = torch.zeros((2, 3, 4), dtype=int)\n",
    "my_tensor[:, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c8c903-72af-4d9c-9f6f-55f5d9679f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_patterns.active_color_order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2401af4e-47f2-43c3-add9-e3a8782a7d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fair_coin(p: float) -> int:\n",
    "    sample1 = random.random()\n",
    "    res1 = 0 if sample1 < p else 1\n",
    "    sprob1 = p if sample1 < p else (1 - p)\n",
    "    num_p1 = run_game(sprob1)\n",
    "    \n",
    "    sample2 = random.random()\n",
    "    res2 = 0 if sample2 < p else 1\n",
    "    sprob2 = p if sample2 < p else (1 - p)\n",
    "    num_p2 = run_game(sprob2, num_p1 + 1)\n",
    "\n",
    "    if num_p1 == num_p2:\n",
    "        if res1 != res2:\n",
    "            return 0\n",
    "            \n",
    "        return 1\n",
    "\n",
    "    return num_p1 > num_p2\n",
    "\n",
    "def run_game(sample_probability: float, num_runs: int = 100000000) -> int:\n",
    "    \"\"\" determine the number of successes before you hit a transition\n",
    "    that is hhhhh...hhht or ttttt..... tttth\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    num = 1\n",
    "    sample = random.random()\n",
    "    \n",
    "    while sample < sample_probability:\n",
    "        num += 1\n",
    "        count += 1\n",
    "        sample = random.random()\n",
    "        \n",
    "        if count >= num_runs:\n",
    "            break\n",
    "\n",
    "    return num\n",
    "        \n",
    "def collect_dist(p: float, num_samples: int) -> int:\n",
    "    res = 0\n",
    "    for it in range(num_samples):\n",
    "        res += int(test_fair_coin(p))\n",
    "\n",
    "    return res\n",
    "\n",
    "num_samples = 1000000\n",
    "res = collect_dist(p=0.2, num_samples=num_samples)\n",
    " \n",
    "res / num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34e4037-735c-4a20-99b5-130bf5572a38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c949bf-389f-4f6e-8a33-81350306c364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9cfec5-33b3-4d5c-8d00-fd704ec9fbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.3\n",
    "q = 1-p\n",
    "n = 1000\n",
    "tot = [0] * n\n",
    "tot2 = [0] * n\n",
    "tot3 = [0] * n\n",
    "tot4 = [0] * n\n",
    "\n",
    "for it in range(1, n + 1):\n",
    "    tot[it - 1] = (q * p ** it + p * q ** it) * (p ** (it + 1) + q ** (it + 1))\n",
    "    tot2[it - 1] = ((q * p ** it + p * q ** it) ** 2) / 2\n",
    "    tot3[it - 1] = p * q * (p ** (2 * it) + q ** (2 * it))\n",
    "    tot4[it - 1] = (p ** 2) * (q ** 2) * (p ** (2 * (it - 1)) + q ** (2 * (it - 1))) / 2\n",
    "\n",
    "print(np.sum(tot) +  np.sum(tot2))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.cumsum(tot) + np.cumsum(tot2))\n",
    "ax.plot(np.cumsum(tot3) + np.cumsum(tot4))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c86f389-54a0-4517-8d3d-1432bd291799",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303cb0e2-f5c9-48b8-9901-704e61c6524d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from int_to_board import location_to_coordinates, orthogonal_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc116462-6ce9-459f-a780-2cf6a56c2e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_to_coordinates, orthogonal_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3262c48a-d91e-4a5f-8d94-c3f001e8d903",
   "metadata": {},
   "outputs": [],
   "source": [
    "huh we only need the tensor state when it is visited for the first time... So when creating the children\n",
    "just create action arguments.\n",
    "Then if child is visited first time, get tensor state if not terminal.\n",
    "Then if child is visited second time, create game.                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d6b29d-41a2-4631-940c-d70ae9a265a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_order = [0, 0, 1, 3, 2, 0]\n",
    "passive_order = [1, 0, 2, 5, 4, 3]\n",
    "\n",
    "ind = [_x - 1 + 6 * _it for _it, _x in enumerate(active_order + passive_order) if _x > 0]\n",
    "np.array(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c5452e-8973-4561-b015-94814ab54862",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tensor = torch.zeros((1, 1, 72))\n",
    "my_tensor[:, :, ind] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d596773f-937f-4d33-a917-34b2f3bcf4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ddbc71-1016-4555-87a5-999352a6a5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b567c1c-a4df-4048-bc38-3a4fa507a904",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
